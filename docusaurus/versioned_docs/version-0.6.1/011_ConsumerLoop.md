
<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
import asyncio
import pytest
from datetime import datetime, timedelta
from unittest.mock import AsyncMock, MagicMock, Mock, call, patch, create_autospec

from pydantic import Field, HttpUrl, NonNegativeInt
from tqdm.notebook import tqdm

from fastkafka._components.helpers import true_after
from fastkafka._components.logger import supress_timestamps
from fastkafka._helpers import produce_messages
from fastkafka.encoder import avro_decoder, avro_encoder, json_decoder
from fastkafka.testing import ApacheKafkaBroker
```

``` python
# allows async calls in notebooks

import nest_asyncio
```

``` python
nest_asyncio.apply()
```

``` python
supress_timestamps()
logger = get_logger(__name__, level=20)
logger.info("ok")
```

    [INFO] __main__: ok

``` python
class MyMessage(BaseModel):
    url: HttpUrl = Field(..., example="http://www.acme.com", description="Url example")
    port: NonNegativeInt = Field(1000)
```

------------------------------------------------------------------------

### EventMetadata

>      EventMetadata (topic:str, partition:int, offset:int, timestamp:int,
>                     timestamp_type:int, key:Optional[bytes],
>                     value:Optional[bytes], checksum:int,
>                     serialized_key_size:int, serialized_value_size:int,
>                     headers:Sequence[Tuple[str,bytes]])

A class for encapsulating Kafka record metadata.

Args: topic: The topic this record is received from partition: The
partition from which this record is received offset: The position of
this record in the corresponding Kafka partition timestamp: The
timestamp of this record timestamp_type: The timestamp type of this
record key: The key (or `None` if no key is specified) value: The value
serialized_key_size: The size of the serialized, uncompressed key in
bytes serialized_value_size: The size of the serialized, uncompressed
value in bytes headers: The headers

``` python
def create_consumer_record(topic: str, partition: int, msg: BaseModel):
    record = ConsumerRecord(
        topic=topic,
        partition=partition,
        offset=0,
        timestamp=0,
        timestamp_type=0,
        key=None,
        value=msg.json().encode("utf-8")
        if hasattr(msg, "json")
        else msg.encode("utf-8"),
        checksum=0,
        serialized_key_size=0,
        serialized_value_size=0,
        headers=[],
    )
    return record
```

``` python
meta = EventMetadata.create_event_metadata(create_consumer_record("topic", 1, MyMessage(url="http://www.acme.com", port=22)))
assert meta.topic == "topic"
assert meta.partition == 1
```

``` python
async def without_meta(msg: BaseModel):
    assert msg == "Example_msg"

with pytest.raises(TypeError) as e:
    await without_meta("Example_msg", "Some_meta")
```

``` python
@_callback_parameters_wrapper
async def without_meta(msg: BaseModel):
    assert msg == "Example_msg"

await without_meta("Example_msg", "Some_meta")
```

``` python
@_callback_parameters_wrapper
async def with_meta(msg: BaseModel, meta: EventMetadata):
    assert msg == "Example_msg"
    assert meta == "Some_meta"

await with_meta("Example_msg", "Some_meta")
```

``` python
# Check if callback is called when wrapped

for is_async in [False, True]:
    example_msg = "Example msg"
    callback = AsyncMock() if is_async else Mock()
    prepared_callback = _prepare_callback(callback)

    with patch("__main__.get_type_hints") as mock:
        mock.return_value = {"msg": BaseModel}
        await prepared_callback(f"{example_msg}", "Some meta")

    callback.assert_called_once_with(f"{example_msg}")
```

``` python
# Sanity check: one msg, one topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic = "topic_0"
    partition = 0
    topic_part_0_0 = TopicPartition(topic, partition)
    msg = MyMessage(url="http://www.acme.com", port=22)
    record = create_consumer_record(topic=topic, partition=partition, msg=msg)

    await _stream_msgs(
        msgs={topic_part_0_0: [record]},
        send_stream=send_stream,
    )

    mock.assert_called_once()
    mock.assert_has_calls([call([record])])
```

``` python
# Check different topics

# Two msg, two topics, send called twice with each topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic_partitions = [("topic_0", 0), ("topic_1", 0)]

    msg = MyMessage(url="http://www.acme.com", port=22)
    msgs = {
        TopicPartition(topic, partition): [
            create_consumer_record(topic=topic, partition=partition, msg=msg)
        ]
        for topic, partition in topic_partitions
    }

    await _stream_msgs(
        msgs=msgs,
        send_stream=send_stream,
    )

    assert mock.call_count == 2

    mock.assert_has_calls([call(msg) for msg in msgs.values()])
```

``` python
# Check multiple msgs in same topic

# Two msg, one topic, send called twice for same topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic_partitions = [("topic_0", 0)]

    msg = MyMessage(url="http://www.acme.com", port=22)
    record = create_consumer_record(topic=topic, partition=partition, msg=msg)

    msgs = {
        TopicPartition(topic, partition): [
            create_consumer_record(topic=topic, partition=partition, msg=msg),
            create_consumer_record(topic=topic, partition=partition, msg=msg),
        ]
        for topic, partition in topic_partitions
    }

    await _stream_msgs(
        msgs=msgs,
        send_stream=send_stream,
    )

    mock.assert_has_calls([call(msg) for msg in msgs.values()])
```

``` python
# Check multiple partitions

# Two msg, one topic, differenct partitions, send called twice for same topic

with patch("anyio.streams.memory.MemoryObjectSendStream.send") as mock:
    send_stream, receive_stream = anyio.create_memory_object_stream()

    topic_partitions = [("topic_0", 0), ("topic_0", 1)]

    msg = MyMessage(url="http://www.acme.com", port=22)
    msgs = {
        TopicPartition(topic, partition): [
            create_consumer_record(topic=topic, partition=partition, msg=msg)
        ]
        for topic, partition in topic_partitions
    }
    record = create_consumer_record(topic=topic, partition=partition, msg=msg)

    await _stream_msgs(
        msgs=msgs,
        send_stream=send_stream,
    )

    mock.assert_has_calls([call(msg) for msg in msgs.values()])
```

``` python
def is_shutting_down_f(mock_func: Mock, num_calls: int = 1) -> Callable[[], bool]:
    def _is_shutting_down_f():
        return mock_func.call_count == num_calls

    return _is_shutting_down_f
```

``` python
topic = "topic_0"
partition = 0
msg = MyMessage(url="http://www.acme.com", port=22)
record = create_consumer_record(topic=topic, partition=partition, msg=msg)

mock_consumer = MagicMock()
msgs = {TopicPartition(topic, 0): [record]}

f = asyncio.Future()
f.set_result(msgs)
mock_consumer.configure_mock(**{"getmany.return_value": f})
mock_callback = Mock()


for is_async in [True, False]:
    for executor_type in ["DynamicTaskExecutor", "SequentialExecutor"]:
        await _aiokafka_consumer_loop(
            consumer=mock_consumer,
            topic=topic,
            decoder_fn=json_decoder,
            max_buffer_size=100,
            timeout_ms=10,
            callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,
            msg_type=MyMessage,
            is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),
            executor_type=executor_type,
        )

        assert mock_consumer.getmany.call_count == 1
        mock_callback.assert_called_once_with(msg)

print("ok")
```

    ok

``` python
# Sanity check: exception in callback recovery
# Two msg, one topic, process_f called twice even tough it throws

for is_async in [True, False]:
    for executor_type in ["DynamicTaskExecutor", "SequentialExecutor"]:
        topic = "topic_0"
        partition = 0
        msg = MyMessage(url="http://www.acme.com", port=22)
        record = create_consumer_record(topic=topic, partition=partition, msg=msg)

        num_msgs = 2

        mock_consumer = MagicMock()
        msgs = {TopicPartition(topic, 0): [record, record]}

        f = asyncio.Future()
        f.set_result(msgs)

        mock_consumer.configure_mock(**{"getmany.return_value": f})
        mock_callback = Mock()

        exception = Exception("")
        mock_callback.side_effect = exception


        await _aiokafka_consumer_loop(
            consumer=mock_consumer,
            topic=topic,
            decoder_fn=json_decoder,
            max_buffer_size=100,
            timeout_ms=1,
            callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,
            msg_type=MyMessage,
            is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany, num_calls=1),
            executor_type=executor_type,
        )

        assert mock_callback.call_count == num_msgs, mock_callback.call_count
        mock_callback.assert_has_calls([call(msg), call(msg)])

print("ok")
```

    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    [WARNING] fastkafka._components.task_streaming: e=Exception('')
    ok

``` python
# Sanity check: malformed msgs
# One msg of wrong type, two normal msg, one topic, process_f called twice

topic = "topic_0"
partition = 0
msg = MyMessage(url="http://www.acme.com", port=22)
correct_record = create_consumer_record(topic=topic, partition=partition, msg=msg)
faulty_record = create_consumer_record(topic=topic, partition=partition, msg="Wrong!")

mock_consumer = MagicMock()
msgs = {TopicPartition(topic, 0): [faulty_record, correct_record, correct_record]}

mock_consumer.configure_mock(**{"getmany.return_value": f})
mock_callback = Mock()

exception = Exception("")
callback.side_effect = exception

for is_async in [True, False]:
    await _aiokafka_consumer_loop(
        consumer=mock_consumer,
        topic=topic,
        decoder_fn=json_decoder,
        max_buffer_size=100,
        timeout_ms=10,
        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,
        msg_type=MyMessage,
        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),
    )

    assert mock_consumer.getmany.call_count == 1
    mock_callback.assert_has_calls([call(msg), call(msg)])

print("ok")
```

    ok

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/aiokafka_consumer_loop.py#L205"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### sanitize_kafka_config

>      sanitize_kafka_config (**kwargs:Any)

Sanitize Kafka config

``` python
kwargs = {
    "bootstrap_servers": "whatever.cloud:9092",
    "auto_offset_reset": "earliest",
    "security_protocol": "SASL_SSL",
    "sasl_mechanism": "PLAIN",
    "sasl_plain_username": "username",
    "sasl_plain_password": "password",
    "ssl_context": "something",
}

assert sanitize_kafka_config(**kwargs)["sasl_plain_password"] == "********"
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/aiokafka_consumer_loop.py#L212"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### aiokafka_consumer_loop

>      aiokafka_consumer_loop (topic:str,
>                              decoder_fn:Callable[[bytes,pydantic.main.ModelMet
>                              aclass],Any], timeout_ms:int=100,
>                              max_buffer_size:int=100000, callback:Union[Callab
>                              le[[pydantic.main.BaseModel],Awaitable[NoneType]]
>                              ,Callable[[pydantic.main.BaseModel,fastkafka.Even
>                              tMetadata],Awaitable[NoneType]],Callable[[pydanti
>                              c.main.BaseModel],NoneType],Callable[[pydantic.ma
>                              in.BaseModel,fastkafka.EventMetadata],NoneType]],
>                              msg_type:Type[pydantic.main.BaseModel],
>                              is_shutting_down_f:Callable[[],bool], executor:Un
>                              ion[str,fastkafka._components.task_streaming.Stre
>                              amExecutor,NoneType]=None, max_records=None,
>                              **kwargs:Any)

Consumer loop for infinite pooling of the AIOKafka consumer for new
messages. Creates and starts AIOKafkaConsumer and runs
\_aio_kafka_consumer loop fo infinite poling of the consumer for new
messages.

Args: topic: name of the topic to subscribe to decoder_fn: Function to
decode the messages consumed from the topic callback: callback function
to be called after decoding and parsing a consumed message timeout_ms:
Time to timeut the getmany request by the consumer max_buffer_size:
Maximum number of unconsumed messages in the callback buffer msg_type:
Type with `parse_json` method used for parsing a decoded message
is_shutting_down_f: Function for controlling the shutdown of consumer
loop callbacks: Dict of callbacks mapped to their respective topics
msg_types: Dict of message types mapped to their respective topics
partitions (list\[TopicPartition\]): The partitions that need fetching
message. If no one partition specified then all subscribed partitions
will be used

``` python
for executor in ["DynamicTaskExecutor", "SequentialExecutor"]:
    topic = "test_topic"
    msgs_sent = 9178
    msgs = [
        MyMessage(url="http://www.ai.com", port=port).json().encode("utf-8")
        for port in range(msgs_sent)
    ]
    msgs_received = 0


    async def count_msg(msg: MyMessage):
        global msgs_received
        msgs_received = msgs_received + 1
        if msgs_received % 1000 == 0:
            logger.info(f"{msgs_received=}")


    async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
        await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
        await aiokafka_consumer_loop(
            topic=topic,
            decoder_fn=json_decoder,
            auto_offset_reset="earliest",
            callback=count_msg,
            msg_type=MyMessage,
            is_shutting_down_f=true_after(2),
            bootstrap_servers=bootstrap_server,
            executor=executor,
        )

        assert msgs_sent == msgs_received, f"{msgs_sent} != {msgs_received}"
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 48208...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 48208 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 47846...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 47846 terminated.
    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 49350...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 49350 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 48989...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 48989 terminated.

``` python
# Test with meta

for executor in ["DynamicTaskExecutor", "SequentialExecutor"]:
    topic = "test_topic"
    msgs_sent = 9178
    msgs = [
        MyMessage(url="http://www.ai.com", port=port).json().encode("utf-8")
        for port in range(msgs_sent)
    ]
    msgs_received = 0
    meta_samples = []

    async def count_msg(msg: MyMessage, meta: EventMetadata):
        global msgs_received
        msgs_received = msgs_received + 1
        if msgs_received % 1000 == 0:
            meta_samples.append(meta)
            logger.info(f"{msgs_received=}, {meta=}")


    async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
        await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
        await aiokafka_consumer_loop(
            topic=topic,
            decoder_fn=json_decoder,
            auto_offset_reset="earliest",
            callback=count_msg,
            msg_type=MyMessage,
            is_shutting_down_f=true_after(2),
            bootstrap_servers=bootstrap_server,
            executor = executor
        )

        assert msgs_sent == msgs_received, f"{msgs_sent} != {msgs_received}"
        assert all(isinstance(meta, EventMetadata) for meta in meta_samples)
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000, meta=EventMetadata(topic='test_topic', partition=0, offset=999, timestamp=1683884722296, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 999}', checksum=None, serialized_key_size=-1, serialized_value_size=41, headers=())
    [INFO] __main__: msgs_received=2000, meta=EventMetadata(topic='test_topic', partition=0, offset=1999, timestamp=1683884722312, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 1999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=3000, meta=EventMetadata(topic='test_topic', partition=0, offset=2999, timestamp=1683884722328, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 2999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=4000, meta=EventMetadata(topic='test_topic', partition=0, offset=3999, timestamp=1683884722343, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 3999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=5000, meta=EventMetadata(topic='test_topic', partition=0, offset=4999, timestamp=1683884722356, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 4999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=6000, meta=EventMetadata(topic='test_topic', partition=0, offset=5999, timestamp=1683884722368, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 5999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=7000, meta=EventMetadata(topic='test_topic', partition=0, offset=6999, timestamp=1683884722381, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 6999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=8000, meta=EventMetadata(topic='test_topic', partition=0, offset=7999, timestamp=1683884722393, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 7999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=9000, meta=EventMetadata(topic='test_topic', partition=0, offset=8999, timestamp=1683884722405, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 8999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 50496...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 50496 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 50133...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 50133 terminated.
    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000, meta=EventMetadata(topic='test_topic', partition=0, offset=999, timestamp=1683884733112, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 999}', checksum=None, serialized_key_size=-1, serialized_value_size=41, headers=())
    [INFO] __main__: msgs_received=2000, meta=EventMetadata(topic='test_topic', partition=0, offset=1999, timestamp=1683884733173, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 1999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=3000, meta=EventMetadata(topic='test_topic', partition=0, offset=2999, timestamp=1683884733187, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 2999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=4000, meta=EventMetadata(topic='test_topic', partition=0, offset=3999, timestamp=1683884733200, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 3999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=5000, meta=EventMetadata(topic='test_topic', partition=0, offset=4999, timestamp=1683884733212, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 4999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=6000, meta=EventMetadata(topic='test_topic', partition=0, offset=5999, timestamp=1683884733225, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 5999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=7000, meta=EventMetadata(topic='test_topic', partition=0, offset=6999, timestamp=1683884733238, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 6999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=8000, meta=EventMetadata(topic='test_topic', partition=0, offset=7999, timestamp=1683884733250, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 7999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: msgs_received=9000, meta=EventMetadata(topic='test_topic', partition=0, offset=8999, timestamp=1683884733263, timestamp_type=0, key=None, value=b'{"url": "http://www.ai.com", "port": 8999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 51641...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 51641 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 51281...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 51281 terminated.

``` python
# Test with avro_decoder

for executor in ["DynamicTaskExecutor", "SequentialExecutor"]:
    topic = "test_topic"
    msgs_sent = 9178
    msgs = [
        avro_encoder(MyMessage(url="http://www.ai.com", port=port))
        for port in range(msgs_sent)
    ]
    msgs_received = 0


    async def count_msg(msg: MyMessage):
        global msgs_received
        msgs_received = msgs_received + 1
        if msgs_received % 1000 == 0:
            logger.info(f"{msgs_received=}")


    async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
        await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
        await aiokafka_consumer_loop(
            topic=topic,
            decoder_fn=avro_decoder,
            auto_offset_reset="earliest",
            callback=count_msg,
            msg_type=MyMessage,
            is_shutting_down_f=true_after(2),
            bootstrap_servers=bootstrap_server,
            executor=executor,
        )

        assert msgs_sent == msgs_received, f"{msgs_sent} != {msgs_received}"
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 52797...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 52797 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 52436...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 52436 terminated.
    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 53937...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 53937 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 53577...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 53577 terminated.

``` python
# Test with avro_decoder and meta

for executor in ["DynamicTaskExecutor", "SequentialExecutor"]:
    topic = "test_topic"
    msgs_sent = 9178
    msgs = [
        avro_encoder(MyMessage(url="http://www.ai.com", port=port))
        for port in range(msgs_sent)
    ]
    msgs_received = 0
    meta_samples = []

    async def count_msg(msg: MyMessage, meta: EventMetadata):
        global msgs_received
        msgs_received = msgs_received + 1
        if msgs_received % 1000 == 0:
            logger.info(f"{msgs_received=}")
            meta_samples.append(meta)


    async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
        await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
        await aiokafka_consumer_loop(
            topic=topic,
            decoder_fn=avro_decoder,
            auto_offset_reset="earliest",
            callback=count_msg,
            msg_type=MyMessage,
            is_shutting_down_f=true_after(2),
            bootstrap_servers=bootstrap_server,
            executor=executor,
        )

        assert msgs_sent == msgs_received, f"{msgs_sent} != {msgs_received}"
        assert all(isinstance(meta, EventMetadata) for meta in meta_samples)
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 55077...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 55077 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 54717...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 54717 terminated.
    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: msgs_received=1000
    [INFO] __main__: msgs_received=2000
    [INFO] __main__: msgs_received=3000
    [INFO] __main__: msgs_received=4000
    [INFO] __main__: msgs_received=5000
    [INFO] __main__: msgs_received=6000
    [INFO] __main__: msgs_received=7000
    [INFO] __main__: msgs_received=8000
    [INFO] __main__: msgs_received=9000
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 56218...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 56218 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 55857...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 55857 terminated.

``` python
for executor in ["DynamicTaskExecutor", "SequentialExecutor"]:
    topic = "test_topic"
    msgs_sent = 500_00
    msgs = [
        MyMessage(url="http://www.ai.com", port=port).json().encode("utf-8")
        for port in range(msgs_sent)
    ]


    async def count_msg(msg: MyMessage):
        pbar.update(1)


    def _is_shutting_down_f():
        return pbar.n >= pbar.total


    async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
        await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
        with tqdm(total=msgs_sent, desc="consuming messages") as _pbar:
            global pbar
            pbar = _pbar

            start = datetime.now()
            await aiokafka_consumer_loop(
                topic=topic,
                decoder_fn=json_decoder,
                auto_offset_reset="earliest",
                callback=count_msg,
                msg_type=MyMessage,
                is_shutting_down_f=_is_shutting_down_f,
                bootstrap_servers=bootstrap_server,
                executor=executor
            )
            t = (datetime.now() - start) / timedelta(seconds=1)
            thrp = pbar.n / t

            print(f"Messages processed: {pbar.n:,d}")
            print(f"Time              : {t:.2f} s")
            print(f"Throughput.       : {thrp:,.0f} msg/s")
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]

    consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    Messages processed: 50,000
    Time              : 4.89 s
    Throughput.       : 10,226 msg/s
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 57361...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 57361 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 56999...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 56999 terminated.
    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]

    consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    Messages processed: 50,000
    Time              : 3.95 s
    Throughput.       : 12,666 msg/s
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 58500...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 58500 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 58140...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 58140 terminated.

``` python
# Test with avro_decoder

for executor in ["DynamicTaskExecutor", "SequentialExecutor"]:
    topic = "test_topic"
    msgs_sent = 500_00
    msgs = [
        avro_encoder(MyMessage(url="http://www.ai.com", port=port))
        for port in range(msgs_sent)
    ]


    async def count_msg(msg: MyMessage):
        pbar.update(1)


    def _is_shutting_down_f():
        return pbar.n >= pbar.total


    async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
        await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
        with tqdm(total=msgs_sent, desc="consuming messages") as _pbar:
            global pbar
            pbar = _pbar

            start = datetime.now()
            await aiokafka_consumer_loop(
                topic=topic,
                decoder_fn=avro_decoder,
                auto_offset_reset="earliest",
                callback=count_msg,
                msg_type=MyMessage,
                is_shutting_down_f=_is_shutting_down_f,
                bootstrap_servers=bootstrap_server,
                executor=executor
            )
            t = (datetime.now() - start) / timedelta(seconds=1)
            thrp = pbar.n / t

            print(f"Messages processed: {pbar.n:,d}")
            print(f"Time              : {t:.2f} s")
            print(f"Throughput.       : {thrp:,.0f} msg/s")
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]

    consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    Messages processed: 50,000
    Time              : 5.95 s
    Throughput.       : 8,399 msg/s
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 59638...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 59638 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 59278...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 59278 terminated.
    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]

    consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    Messages processed: 50,000
    Time              : 5.12 s
    Throughput.       : 9,758 msg/s
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 60795...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 60795 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 60434...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 60434 terminated.

## Consumer loop benchmark and coroutine sanity check

``` python
topic = "test_topic"
msgs_sent = 500_00
msgs = [
    MyMessage(url="http://www.ai.com", port=port).json().encode("utf-8")
    for port in range(msgs_sent)
]


async def count_msg(msg: MyMessage):
    pbar.update(1)
    await asyncio.sleep(1)
    pbar.update(1)

def _is_shutting_down_f():
    return pbar.n >= pbar.total


async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:
    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)
    with tqdm(total=msgs_sent*2, desc="consuming messages") as _pbar:
        global pbar
        pbar = _pbar

        start = datetime.now()
        await aiokafka_consumer_loop(
            topic=topic,
            decoder_fn=json_decoder,
            auto_offset_reset="earliest",
            callback=count_msg,
            msg_type=MyMessage,
            is_shutting_down_f=_is_shutting_down_f,
            bootstrap_servers=bootstrap_server,
            executor = "DynamicTaskExecutor"
        )
        t = (datetime.now() - start) / timedelta(seconds=1)
        thrp = pbar.n / t

        print(f"Messages processed: {pbar.n:,d}")
        print(f"Time              : {t:.2f} s")
        print(f"Throughput.       : {thrp:,.0f} msg/s")
        
assert t < 15
```

    [INFO] fastkafka._components.test_dependencies: Java is already installed.
    [INFO] fastkafka._components.test_dependencies: Kafka is installed.
    [INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...
    [INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...
    [INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092

    producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]

    consuming messages:   0%|          | 0/100000 [00:00<?, ?it/s]

    [INFO] __main__: aiokafka_consumer_loop() starting...
    [INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer started.
    [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})
    [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}
    [INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.
    [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. 
    [INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.
    [INFO] __main__: aiokafka_consumer_loop() finished.
    Messages processed: 100,000
    Time              : 8.13 s
    Throughput.       : 12,295 msg/s
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 61938...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 61938 terminated.
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 61578...
    [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 61578 terminated.
