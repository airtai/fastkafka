Fastcore replacement: patch & delegates
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
from contextlib import contextmanager

from aiokafka import AIOKafkaConsumer
```

## Patching

> copied from
> https://github.com/fastai/fastcore/blob/master/nbs/01_basics.ipynb

``` python
def foo():
    """Test doc"""
    pass


a = cp.copy(foo)
b = cp.deepcopy(foo)

a.someattr = "hello"  # since a and b point at the same object, updating a will update b
test_eq(b.someattr, "hello")

assert a is foo and b is foo
```

However, with copy_func, you can retrieve a copy of a function without a
reference to the original object:

``` python
c = copy_func(foo)  # c is an indpendent object
assert c is not foo
assert c.__doc__ == """Test doc""", c.__doc__
```

``` python
def g(x, *, y=3):
    return x + y


test_eq(copy_func(g)(4), 7)
```

``` python
class _T3(int):
    pass


@patch_to(_T3)
def foo(self):
    """Test doc"""
    pass


assert _T3.foo.__doc__ == """Test doc""", foo.__doc__
```

The @patch_to decorator allows you to monkey patch a function into a
class as a method:

``` python
class _T3(int):
    pass


@patch_to(_T3)
def func1(self, a):
    return self + a


t = _T3(1)  # we initilized `t` to a type int = 1
test_eq(t.func1(2), 3)  # we add 2 to `t`, so 2 + 1 = 3
```

You can access instance properties in the usual way via self:

``` python
class _T4:
    def __init__(self, g):
        self.g = g


@patch_to(_T4)
def greet(self, x):
    return self.g + x


t = _T4("hello ")  # this sets self.g = 'helllo '
test_eq(
    t.greet("world"), "hello world"
)  # t.greet('world') will append 'world' to 'hello '
```

You can instead specify that the method should be a class method by
setting cls_method=True:

``` python
class _T5(int):
    attr = 3  # attr is a class attribute we will access in a later method


@patch_to(_T5, cls_method=True)
def func(cls, x):
    return cls.attr + x  # you can access class attributes in the normal way


test_eq(_T5.func(4), 7)
```

``` python
# Additionally you can specify that the function you want to patch should be a class attribute with as_prop=True:


@patch_to(_T5, as_prop=True)
def add_ten(self):
    return self + 10


t = _T5(4)
test_eq(t.add_ten, 14)
```

Instead of passing one class to the @patch_to decorator, you can pass
multiple classes in a tuple to simulteanously patch more than one class
with the same method:

``` python
class _T6(int):
    pass


class _T7(int):
    pass


@patch_to((_T6, _T7))
def func_mult(self, a):
    return self * a


t = _T6(2)
test_eq(t.func_mult(4), 8)
t = _T7(2)
test_eq(t.func_mult(4), 8)
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/meta.py#L159"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### patch

>      patch (f:Optional[~F]=None, as_prop:bool=False, cls_method:bool=False)

Decorator: add `f` to the first parameter’s class (based on f’s type
annotations)

|            | **Type** | **Default** | **Details**  |
|------------|----------|-------------|--------------|
| f          | Optional | None        | type: ignore |
| as_prop    | bool     | False       |              |
| cls_method | bool     | False       |              |

``` python
class _T8(int):
    pass


@patch
def func(self: _T8, a):
    """Test doc"""
    return self + a


assert _T8.func.__doc__ == """Test doc""", func.__doc__
```

@patch is an alternative to @patch_to that allows you similarly monkey
patch class(es) by using type annotations:

``` python
class _T8(int):
    pass


@patch
def func(self: _T8, a):
    return self + a


t = _T8(1)  # we initilized `t` to a type int = 1
test_eq(t.func(3), 4)  # we add 3 to `t`, so 3 + 1 = 4
test_eq(t.func.__qualname__, "_T8.func")
```

Similarly to patch_to, you can supply a union of classes instead of a
single class in your type annotations to patch multiple classes:

``` python
class _T9(int):
    pass


@patch
def func2(x: Union[_T8, _T9], a):
    return x * a  # will patch both _T8 and _T9


t = _T8(2)
test_eq(t.func2(4), 8)
test_eq(t.func2.__qualname__, "_T8.func2")

t = _T9(2)
test_eq(t.func2(4), 8)
test_eq(t.func2.__qualname__, "_T9.func2")
```

Just like patch_to decorator you can use as_prop and cls_method
parameters with patch decorator:

``` python
@patch(as_prop=True)
def add_ten(self: _T5):
    return self + 10


t = _T5(4)
test_eq(t.add_ten, 14)
```

``` python
class _T5(int):
    attr = 3  # attr is a class attribute we will access in a later method


@patch(cls_method=True)
def func(cls: _T5, x):
    return cls.attr + x  # you can access class attributes in the normal way


test_eq(_T5.func(4), 7)
```

``` python
print("ok")
```

    ok

``` python
def test_sig(f, b):
    "Test the signature of an object"
    if str(inspect.signature(f)) != b:
        raise ValueError(f"{inspect.signature(f)} != {b}")
```

# Fastcore meta deps

> Copied from
> https://github.com/fastai/fastcore/blob/master/nbs/07_meta.ipynb

A common Python idiom is to accept **kwargs in addition to named
parameters that are passed onto other function calls. It is especially
common to use **kwargs when you want to give the user an option to
override default parameters of any functions or methods being called by
the parent function.

For example, suppose we have have a function foo that passes arguments
to baz like so:

``` python
def baz(a, b: int = 2, c: int = 3) -> int:
    """Baz
    Params:
        a: something
        b: whatever
        c: whocares

    Returns:
        Nada
    """
    return a + b + c


def foo(c, a, **kwargs):
    return c + baz(a, **kwargs)


assert foo(c=1, a=1) == 7
```

The problem with this approach is the api for foo is obfuscated. Users
cannot introspect what the valid arguments for \*\*kwargs are without
reading the source code. When a user tries tries to introspect the
signature of foo, they are presented with this:

``` python
inspect.signature(foo)
```

    <Signature (c, a, **kwargs)>

``` python
inspect.signature(baz)
```

    <Signature (a, b: int = 2, c: int = 3) -> int>

``` python
print(baz.__doc__)
```

    Baz
        Params:
            a: something
            b: whatever
            c: whocares

        Returns:
            Nada
        

We can address this issue by using the decorator delegates to include
parameters from other functions. For example, if we apply the delegates
decorator to foo to include parameters from baz:

``` python
@_delegates_without_docs(baz)
def foo(c, a, **kwargs):
    """Foo is great

    Params:
        c: c from foo
        a: a from foo
    """
    return c + baz(a, **kwargs)


test_sig(foo, "(c, a, *, b: int = 2)")
assert (
    foo.__doc__
    == "Foo is great\n\n    Params:\n        c: c from foo\n        a: a from foo\n    "
)
inspect.signature(foo)
```

    <Signature (c, a, *, b: int = 2)>

``` python
foo.__doc__
```

    'Foo is great\n\n    Params:\n        c: c from foo\n        a: a from foo\n    '

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/meta.py#L225"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### combine_params

>      combine_params (f:~F, o:Union[Type,Callable[...,Any]],
>                      but:Optional[List[str]]=None)

Combines docstring arguments of a function and another object or
function

Args: f: destination functions where combined arguments will end up o:
source function from which arguments are taken from

Returns: Function f with augumented docstring including arguments from
both functions/objects

``` python
def f2(a: int = 0, b: str = "nada"):
    """
    Args:
        a: parameter a
        b: parameter bbbb
    """


def f1(b: str, c: int, **kwargs):
    """Function f1
    Args:
        b: parameter b
        c: parameter c

    Raises:
        ValueError: sometimes
    """


combine_params(f1, f2).__doc__

expected = """Function f1
Args:
    b: parameter b
    c: parameter c
    a: parameter a

Raises:
    ValueError: sometimes"""

assert f1.__doc__ == expected
```

``` python
# Add test case to test combine_params with 'but' param


def f2(a: int = 0, b: str = "nada", d: str = "dada"):
    """
    Args:
        a: parameter a
        b: parameter bbbb
        d: parameter d
    """


def f1(b: str, c: int):
    """Function f1
    Args:
        b: parameter b
        c: parameter c

    Raises:
        ValueError: sometimes
    """


combine_params(f1, f2, but=["d"]).__doc__

expected = """Function f1
Args:
    b: parameter b
    c: parameter c
    a: parameter a

Raises:
    ValueError: sometimes"""

assert f1.__doc__ == expected, f1.__doc__
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/meta.py#L263"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### delegates

>      delegates (o:Union[Type,Callable[...,Any]], keep:bool=False,
>                 but:Optional[List[str]]=None)

Delegates keyword agruments from o to the function the decorator is
applied to

Args: o: object (class or function) with default kwargs keep: Keep
`kwargs` in decorated function? but: argument names not to include

``` python
def f2(a: str = "whatever", d: int = 42) -> None:
    """
    Args:
        a: parameter a
        b: parameter bbbb
    """
    pass


@delegates(f2)
def f1(b: str, c: int, **kwargs):
    """Function f1
    Args:
        b: parameter b
        c: parameter c

    Raises:
        ValueError: sometimes
    """
    pass


expected = """Function f1
Args:
    b: parameter b
    c: parameter c
    a: parameter a

Raises:
    ValueError: sometimes"""

assert f1.__doc__ == expected
assert len(inspect.signature(f2).parameters) == 2
assert len(inspect.signature(f1).parameters) == 4
```

``` python
# Add test case to test delegates with 'but' param


def p1(a: int = 0, b: float = 0.1):
    """Func p1
    Args:
        a: hello
        b: bello
    """
    pass


@delegates(p1, but=["b"])
def p2(c: int, d: float):
    """Func p2
    Args:
        c: cello
        d: dello
    """
    pass


expected = """Func p2
Args:
    c: cello
    d: dello
    a: hello"""

assert p2.__doc__ == expected, p2.__doc__
assert len(inspect.signature(p2).parameters) == 3
assert len(inspect.signature(p1).parameters) == 2
```

``` python
@delegates(f2)
def f3(b: str, c: int, **kwargs):
    """Function f1
    Args:
        b: parameter b
        c: parameter c

    Raises:
        ValueError: sometimes
    """
    pass


params = inspect.signature(f3).parameters
display(params)
assert len(params) == 4
```

    mappingproxy({'b': <Parameter "b: str">,
                  'c': <Parameter "c: int">,
                  'a': <Parameter "a: str = 'whatever'">,
                  'd': <Parameter "d: int = 42">})

``` python
@delegates(AIOKafkaConsumer)
def f(a: int, **kwargs) -> str:
    """function a

    Args:
        a: parameter a

    Returns:
        things not stuff
    """
    print(f"{a=}")


assert len(f.__doc__) > 5000

print(f.__doc__)
```

    function a

    Args:
        a: parameter a
        *topics (list(str)): optional list of topics to subscribe to. If not set,
            call :meth:`.subscribe` or :meth:`.assign` before consuming records.
            Passing topics directly is same as calling :meth:`.subscribe` API.
        bootstrap_servers (str, list(str)): a ``host[:port]`` string (or list of
            ``host[:port]`` strings) that the consumer should contact to bootstrap
            initial cluster metadata.
            
            This does not have to be the full node list.
            It just needs to have at least one broker that will respond to a
            Metadata API Request. Default port is 9092. If no servers are
            specified, will default to ``localhost:9092``.
        client_id (str): a name for this client. This string is passed in
            each request to servers and can be used to identify specific
            server-side log entries that correspond to this client. Also
            submitted to :class:`~.consumer.group_coordinator.GroupCoordinator`
            for logging with respect to consumer group administration. Default:
            ``aiokafka-{version}``
        group_id (str or None): name of the consumer group to join for dynamic
            partition assignment (if enabled), and to use for fetching and
            committing offsets. If None, auto-partition assignment (via
            group coordinator) and offset commits are disabled.
            Default: None
        key_deserializer (Callable): Any callable that takes a
            raw message key and returns a deserialized key.
        value_deserializer (Callable, Optional): Any callable that takes a
            raw message value and returns a deserialized value.
        fetch_min_bytes (int): Minimum amount of data the server should
            return for a fetch request, otherwise wait up to
            `fetch_max_wait_ms` for more data to accumulate. Default: 1.
        fetch_max_bytes (int): The maximum amount of data the server should
            return for a fetch request. This is not an absolute maximum, if
            the first message in the first non-empty partition of the fetch
            is larger than this value, the message will still be returned
            to ensure that the consumer can make progress. NOTE: consumer
            performs fetches to multiple brokers in parallel so memory
            usage will depend on the number of brokers containing
            partitions for the topic.
            Supported Kafka version >= 0.10.1.0. Default: 52428800 (50 Mb).
        fetch_max_wait_ms (int): The maximum amount of time in milliseconds
            the server will block before answering the fetch request if
            there isn't sufficient data to immediately satisfy the
            requirement given by fetch_min_bytes. Default: 500.
        max_partition_fetch_bytes (int): The maximum amount of data
            per-partition the server will return. The maximum total memory
            used for a request ``= #partitions * max_partition_fetch_bytes``.
            This size must be at least as large as the maximum message size
            the server allows or else it is possible for the producer to
            send messages larger than the consumer can fetch. If that
            happens, the consumer can get stuck trying to fetch a large
            message on a certain partition. Default: 1048576.
        max_poll_records (int): The maximum number of records returned in a
            single call to :meth:`.getmany`. Defaults ``None``, no limit.
        request_timeout_ms (int): Client request timeout in milliseconds.
            Default: 40000.
        retry_backoff_ms (int): Milliseconds to backoff when retrying on
            errors. Default: 100.
        auto_offset_reset (str): A policy for resetting offsets on
            :exc:`.OffsetOutOfRangeError` errors: ``earliest`` will move to the oldest
            available message, ``latest`` will move to the most recent, and
            ``none`` will raise an exception so you can handle this case.
            Default: ``latest``.
        enable_auto_commit (bool): If true the consumer's offset will be
            periodically committed in the background. Default: True.
        auto_commit_interval_ms (int): milliseconds between automatic
            offset commits, if enable_auto_commit is True. Default: 5000.
        check_crcs (bool): Automatically check the CRC32 of the records
            consumed. This ensures no on-the-wire or on-disk corruption to
            the messages occurred. This check adds some overhead, so it may
            be disabled in cases seeking extreme performance. Default: True
        metadata_max_age_ms (int): The period of time in milliseconds after
            which we force a refresh of metadata even if we haven't seen any
            partition leadership changes to proactively discover any new
            brokers or partitions. Default: 300000
        partition_assignment_strategy (list): List of objects to use to
            distribute partition ownership amongst consumer instances when
            group management is used. This preference is implicit in the order
            of the strategies in the list. When assignment strategy changes:
            to support a change to the assignment strategy, new versions must
            enable support both for the old assignment strategy and the new
            one. The coordinator will choose the old assignment strategy until
            all members have been updated. Then it will choose the new
            strategy. Default: [:class:`.RoundRobinPartitionAssignor`]
        max_poll_interval_ms (int): Maximum allowed time between calls to
            consume messages (e.g., :meth:`.getmany`). If this interval
            is exceeded the consumer is considered failed and the group will
            rebalance in order to reassign the partitions to another consumer
            group member. If API methods block waiting for messages, that time
            does not count against this timeout. See `KIP-62`_ for more
            information. Default 300000
        rebalance_timeout_ms (int): The maximum time server will wait for this
            consumer to rejoin the group in a case of rebalance. In Java client
            this behaviour is bound to `max.poll.interval.ms` configuration,
            but as ``aiokafka`` will rejoin the group in the background, we
            decouple this setting to allow finer tuning by users that use
            :class:`.ConsumerRebalanceListener` to delay rebalacing. Defaults
            to ``session_timeout_ms``
        session_timeout_ms (int): Client group session and failure detection
            timeout. The consumer sends periodic heartbeats
            (`heartbeat.interval.ms`) to indicate its liveness to the broker.
            If no hearts are received by the broker for a group member within
            the session timeout, the broker will remove the consumer from the
            group and trigger a rebalance. The allowed range is configured with
            the **broker** configuration properties
            `group.min.session.timeout.ms` and `group.max.session.timeout.ms`.
            Default: 10000
        heartbeat_interval_ms (int): The expected time in milliseconds
            between heartbeats to the consumer coordinator when using
            Kafka's group management feature. Heartbeats are used to ensure
            that the consumer's session stays active and to facilitate
            rebalancing when new consumers join or leave the group. The
            value must be set lower than `session_timeout_ms`, but typically
            should be set no higher than 1/3 of that value. It can be
            adjusted even lower to control the expected time for normal
            rebalances. Default: 3000
        consumer_timeout_ms (int): maximum wait timeout for background fetching
            routine. Mostly defines how fast the system will see rebalance and
            request new data for new partitions. Default: 200
        api_version (str): specify which kafka API version to use.
            :class:`AIOKafkaConsumer` supports Kafka API versions >=0.9 only.
            If set to ``auto``, will attempt to infer the broker version by
            probing various APIs. Default: ``auto``
        security_protocol (str): Protocol used to communicate with brokers.
            Valid values are: ``PLAINTEXT``, ``SSL``. Default: ``PLAINTEXT``.
        ssl_context (ssl.SSLContext): pre-configured :class:`~ssl.SSLContext`
            for wrapping socket connections. Directly passed into asyncio's
            :meth:`~asyncio.loop.create_connection`. For more information see
            :ref:`ssl_auth`. Default: None.
        exclude_internal_topics (bool): Whether records from internal topics
            (such as offsets) should be exposed to the consumer. If set to True
            the only way to receive records from an internal topic is
            subscribing to it. Requires 0.10+ Default: True
        connections_max_idle_ms (int): Close idle connections after the number
            of milliseconds specified by this config. Specifying `None` will
            disable idle checks. Default: 540000 (9 minutes).
        isolation_level (str): Controls how to read messages written
            transactionally.
            
            If set to ``read_committed``, :meth:`.getmany` will only return
            transactional messages which have been committed.
            If set to ``read_uncommitted`` (the default), :meth:`.getmany` will
            return all messages, even transactional messages which have been
            aborted.
            
            Non-transactional messages will be returned unconditionally in
            either mode.
            
            Messages will always be returned in offset order. Hence, in
            `read_committed` mode, :meth:`.getmany` will only return
            messages up to the last stable offset (LSO), which is the one less
            than the offset of the first open transaction. In particular any
            messages appearing after messages belonging to ongoing transactions
            will be withheld until the relevant transaction has been completed.
            As a result, `read_committed` consumers will not be able to read up
            to the high watermark when there are in flight transactions.
            Further, when in `read_committed` the seek_to_end method will
            return the LSO. See method docs below. Default: ``read_uncommitted``
        sasl_mechanism (str): Authentication mechanism when security_protocol
            is configured for ``SASL_PLAINTEXT`` or ``SASL_SSL``. Valid values are:
            ``PLAIN``, ``GSSAPI``, ``SCRAM-SHA-256``, ``SCRAM-SHA-512``,
            ``OAUTHBEARER``.
            Default: ``PLAIN``
        sasl_plain_username (str): username for SASL ``PLAIN`` authentication.
            Default: None
        sasl_plain_password (str): password for SASL ``PLAIN`` authentication.
            Default: None
        sasl_oauth_token_provider (~aiokafka.abc.AbstractTokenProvider): OAuthBearer token provider instance. (See :mod:`kafka.oauth.abstract`).
            Default: None

    Returns:
        : things not stuff

``` python
inspect.signature(f).parameters
```

    mappingproxy({'a': <Parameter "a: int">,
                  'loop': <Parameter "loop=None">,
                  'bootstrap_servers': <Parameter "bootstrap_servers='localhost'">,
                  'client_id': <Parameter "client_id='aiokafka-0.8.0'">,
                  'group_id': <Parameter "group_id=None">,
                  'key_deserializer': <Parameter "key_deserializer=None">,
                  'value_deserializer': <Parameter "value_deserializer=None">,
                  'fetch_max_wait_ms': <Parameter "fetch_max_wait_ms=500">,
                  'fetch_max_bytes': <Parameter "fetch_max_bytes=52428800">,
                  'fetch_min_bytes': <Parameter "fetch_min_bytes=1">,
                  'max_partition_fetch_bytes': <Parameter "max_partition_fetch_bytes=1048576">,
                  'request_timeout_ms': <Parameter "request_timeout_ms=40000">,
                  'retry_backoff_ms': <Parameter "retry_backoff_ms=100">,
                  'auto_offset_reset': <Parameter "auto_offset_reset='latest'">,
                  'enable_auto_commit': <Parameter "enable_auto_commit=True">,
                  'auto_commit_interval_ms': <Parameter "auto_commit_interval_ms=5000">,
                  'check_crcs': <Parameter "check_crcs=True">,
                  'metadata_max_age_ms': <Parameter "metadata_max_age_ms=300000">,
                  'partition_assignment_strategy': <Parameter "partition_assignment_strategy=(<class 'kafka.coordinator.assignors.roundrobin.RoundRobinPartitionAssignor'>,)">,
                  'max_poll_interval_ms': <Parameter "max_poll_interval_ms=300000">,
                  'rebalance_timeout_ms': <Parameter "rebalance_timeout_ms=None">,
                  'session_timeout_ms': <Parameter "session_timeout_ms=10000">,
                  'heartbeat_interval_ms': <Parameter "heartbeat_interval_ms=3000">,
                  'consumer_timeout_ms': <Parameter "consumer_timeout_ms=200">,
                  'max_poll_records': <Parameter "max_poll_records=None">,
                  'ssl_context': <Parameter "ssl_context=None">,
                  'security_protocol': <Parameter "security_protocol='PLAINTEXT'">,
                  'api_version': <Parameter "api_version='auto'">,
                  'exclude_internal_topics': <Parameter "exclude_internal_topics=True">,
                  'connections_max_idle_ms': <Parameter "connections_max_idle_ms=540000">,
                  'isolation_level': <Parameter "isolation_level='read_uncommitted'">,
                  'sasl_mechanism': <Parameter "sasl_mechanism='PLAIN'">,
                  'sasl_plain_password': <Parameter "sasl_plain_password=None">,
                  'sasl_plain_username': <Parameter "sasl_plain_username=None">,
                  'sasl_kerberos_service_name': <Parameter "sasl_kerberos_service_name='kafka'">,
                  'sasl_kerberos_domain_name': <Parameter "sasl_kerberos_domain_name=None">,
                  'sasl_oauth_token_provider': <Parameter "sasl_oauth_token_provider=None">})

We can optionally decide to keep \*\*kwargs by setting keep=True:

``` python
@delegates(baz, keep=True)
def foo(c, a, **kwargs):
    return c + baz(a, **kwargs)


inspect.signature(foo)
```

    <Signature (c, a, *, b: int = 2, **kwargs)>

It is important to note that only parameters with default parameters are
included. For example, in the below scenario only c, but NOT e and d are
included in the signature of foo after applying delegates:

``` python
def basefoo(e, d, c=2):
    pass


@delegates(basefoo)
def foo(a, b=1, **kwargs):
    pass


inspect.signature(
    foo
)  # e and d are not included b/c they don't have default parameters.
```

    <Signature (a, b=1, *, c=2)>

The reason that required arguments (i.e. those without default
parameters) are automatically excluded is that you should be explicitly
implementing required arguments into your function’s signature rather
than relying on delegates.

Additionally, you can exclude specific parameters from being included in
the signature with the but parameter. In the example below, we exclude
the parameter d:

``` python
def basefoo(e, c=2, d=3):
    pass


@delegates(basefoo, but=["d"])
def foo(a, b=1, **kwargs):
    pass


test_sig(foo, "(a, b=1, *, c=2)")
inspect.signature(foo)
```

    <Signature (a, b=1, *, c=2)>

You can also use delegates between methods in a class. Here is an
example of delegates with class methods:

``` python
# example 1: class methods
class _T:
    @classmethod
    def foo(cls, a=1, b=2):
        pass

    @classmethod
    @delegates(foo)
    def bar(cls, c=3, **kwargs):
        pass


test_sig(_T.bar, "(c=3, *, a=1, b=2)")
```

Here is the same example with instance methods:

``` python
# example 2: instance methods
class _T:
    def foo(self, a=1, b=2):
        pass

    @delegates(foo)
    def bar(self, c=3, **kwargs):
        pass


t = _T()
test_sig(t.bar, "(c=3, *, a=1, b=2)")
```

You can also delegate between classes. By default, the delegates
decorator will delegate to the superclass:

``` python
# class BaseFoo:
#     def __init__(self, e, c=2): pass

# @delegates()# since no argument was passsed here we delegate to the superclass
# class Foo(BaseFoo):
#     def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs)

# test_sig(Foo, '(a, b=1, *, c=2)')
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/meta.py#L300"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### use_parameters_of

>      use_parameters_of (o:Union[Type,Callable[...,Any]],
>                         **kwargs:Dict[str,Any])

Restrict parameters passwed as keyword arguments to parameters from the
signature of `o`

Args: o: object or callable which signature is used for restricting
keyword arguments kwargs: keyword arguments

Returns: restricted keyword arguments

``` python
assert use_parameters_of(AIOKafkaConsumer, api_version=0.1, radnom_param="random") == {
    "api_version": 0.1
}
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/meta.py#L317"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### filter_using_signature

>      filter_using_signature (f:Callable, **kwargs:Dict[str,Any])

todo: write docs

``` python
def f(a: int, *, b: str):
    pass


assert filter_using_signature(f, a=1, c=3) == {"a": 1}
```

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/meta.py#L326"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### export

>      export (module_name:str)

``` python
@export("super.cool")
class A:
    pass


assert A.__module__ == "super.cool"
```

# Class context manager

------------------------------------------------------------------------

<a
href="https://github.com/airtai/fastkafka/blob/main/fastkafka/_components/meta.py#L337"
target="_blank" style={{float: 'right', fontSize: 'smaller'}}>source</a>

### classcontextmanager

>      classcontextmanager (name:str='lifecycle')

``` python
@classcontextmanager("lifecycle")
class A:
    @contextmanager
    def lifecycle(self):
        try:
            print("I'm in")
            yield
        finally:
            print("I'm out")
```

``` python
a = A()
with a:
    with a:
        pass
```

    I'm in
    I'm in
    I'm out
    I'm out

``` python
def A(c: int, b: str = "default", d: float = 3.14):
    pass


assert _get_default_kwargs_from_sig(A) == {"b": "default", "d": 3.14}
assert _get_default_kwargs_from_sig(A, d=5.15) == {"b": "default", "d": 5.15}
```
