"use strict";(self.webpackChunkfastkafka=self.webpackChunkfastkafka||[]).push([[7368],{3905:(e,a,o)=>{o.d(a,{Zo:()=>c,kt:()=>d});var t=o(7294);function n(e,a,o){return a in e?Object.defineProperty(e,a,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[a]=o,e}function s(e,a){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),o.push.apply(o,t)}return o}function r(e){for(var a=1;a<arguments.length;a++){var o=null!=arguments[a]?arguments[a]:{};a%2?s(Object(o),!0).forEach((function(a){n(e,a,o[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):s(Object(o)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(o,a))}))}return e}function l(e,a){if(null==e)return{};var o,t,n=function(e,a){if(null==e)return{};var o,t,n={},s=Object.keys(e);for(t=0;t<s.length;t++)o=s[t],a.indexOf(o)>=0||(n[o]=e[o]);return n}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(t=0;t<s.length;t++)o=s[t],a.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var i=t.createContext({}),p=function(e){var a=t.useContext(i),o=a;return e&&(o="function"==typeof e?e(a):r(r({},a),e)),o},c=function(e){var a=p(e.components);return t.createElement(i.Provider,{value:a},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},k=t.forwardRef((function(e,a){var o=e.components,n=e.mdxType,s=e.originalType,i=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=p(o),k=n,d=m["".concat(i,".").concat(k)]||m[k]||u[k]||s;return o?t.createElement(d,r(r({ref:a},c),{},{components:o})):t.createElement(d,r({ref:a},c))}));function d(e,a){var o=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var s=o.length,r=new Array(s);r[0]=k;var l={};for(var i in a)hasOwnProperty.call(a,i)&&(l[i]=a[i]);l.originalType=e,l[m]="string"==typeof e?e:n,r[1]=l;for(var p=2;p<s;p++)r[p]=o[p];return t.createElement.apply(null,r)}return t.createElement.apply(null,o)}k.displayName="MDXCreateElement"},4261:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>i,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>p});var t=o(7462),n=(o(7294),o(3905));const s={},r="@consumes basics",l={unversionedId:"guides/Guide_11_Consumes_Basics",id:"guides/Guide_11_Consumes_Basics",title:"@consumes basics",description:"You can use @consumes decorator to consume messages from Kafka topics.",source:"@site/docs/guides/Guide_11_Consumes_Basics.md",sourceDirName:"guides",slug:"/guides/Guide_11_Consumes_Basics",permalink:"/docs/next/guides/Guide_11_Consumes_Basics",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"FastKafka",permalink:"/docs/next/"},next:{title:"Batch consuming",permalink:"/docs/next/guides/Guide_12_Batch_Consuming"}},i={},p=[{value:"Import <code>FastKafka</code>",id:"import-fastkafka",level:2},{value:"Define the structure of the messages",id:"define-the-structure-of-the-messages",level:2},{value:"Create a base FastKafka app",id:"create-a-base-fastkafka-app",level:2},{value:"Create a consumer function and decorate it with <code>@consumes</code>",id:"create-a-consumer-function-and-decorate-it-with-consumes",level:2},{value:"Final app",id:"final-app",level:2},{value:"Run the app",id:"run-the-app",level:2},{value:"Send the message to kafka topic",id:"send-the-message-to-kafka-topic",level:2},{value:"Choosing a topic",id:"choosing-a-topic",level:2},{value:"Message data",id:"message-data",level:2},{value:"Message metadata",id:"message-metadata",level:2},{value:"Create a consumer function with metadata",id:"create-a-consumer-function-with-metadata",level:3},{value:"Dealing with high latency consuming functions",id:"dealing-with-high-latency-consuming-functions",level:2}],c={toc:p},m="wrapper";function u(e){let{components:a,...o}=e;return(0,n.kt)(m,(0,t.Z)({},c,o,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"consumes-basics"},"@consumes basics"),(0,n.kt)("p",null,"You can use ",(0,n.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator to consume messages from Kafka topics."),(0,n.kt)("p",null,"In this guide we will create a simple FastKafka app that will consume\n",(0,n.kt)("inlineCode",{parentName:"p"},"HelloWorld")," messages from hello_world topic."),(0,n.kt)("h2",{id:"import-fastkafka"},"Import ",(0,n.kt)("a",{parentName:"h2",href:"/docs/next/api/fastkafka/#fastkafka.FastKafka"},(0,n.kt)("inlineCode",{parentName:"a"},"FastKafka"))),(0,n.kt)("p",null,"To use the ",(0,n.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator, first we need to import the base\nFastKafka app to create our application."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"from fastkafka import FastKafka\n")),(0,n.kt)("p",null,"In this demo we will log the messages to the output so that we can\ninspect and verify that our app is consuming properly. For that we need\nto import the logger."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"from fastkafka._components.logger import get_logger\n\nlogger = get_logger(__name__)\n")),(0,n.kt)("h2",{id:"define-the-structure-of-the-messages"},"Define the structure of the messages"),(0,n.kt)("p",null,"Next, you need to define the structure of the messages you want to\nconsume from the topic using ",(0,n.kt)("a",{parentName:"p",href:"https://docs.pydantic.dev/"},"pydantic"),". For\nthe guide we\u2019ll stick to something basic, but you are free to define any\ncomplex message structure you wish in your project, just make sure it\ncan be JSON encoded."),(0,n.kt)("p",null,"Let\u2019s import ",(0,n.kt)("inlineCode",{parentName:"p"},"BaseModel")," and ",(0,n.kt)("inlineCode",{parentName:"p"},"Field")," from pydantic and create a simple\n",(0,n.kt)("inlineCode",{parentName:"p"},"HelloWorld")," class containing one string parameter ",(0,n.kt)("inlineCode",{parentName:"p"},"msg")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"from pydantic import BaseModel, Field\n")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'class HelloWorld(BaseModel):\n    msg: str = Field(\n        ...,\n        example="Hello",\n        description="Demo hello world message",\n    )\n')),(0,n.kt)("h2",{id:"create-a-base-fastkafka-app"},"Create a base FastKafka app"),(0,n.kt)("p",null,"Now we will create and define a base FastKafka app, replace the\n",(0,n.kt)("inlineCode",{parentName:"p"},"<url_of_your_kafka_bootstrap_server>")," and\n",(0,n.kt)("inlineCode",{parentName:"p"},"<port_of_your_kafka_bootstrap_server>")," with the actual values of your\nKafka bootstrap server"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'kafka_brokers = {\n    "demo_broker": {\n        "url": "<url_of_your_kafka_bootstrap_server>",\n        "description": "local demo kafka broker",\n        "port": "<port_of_your_kafka_bootstrap_server>",\n    }\n}\n\napp = FastKafka(kafka_brokers=kafka_brokers)\n')),(0,n.kt)("h2",{id:"create-a-consumer-function-and-decorate-it-with-consumes"},"Create a consumer function and decorate it with ",(0,n.kt)("inlineCode",{parentName:"h2"},"@consumes")),(0,n.kt)("p",null,"Let\u2019s create a consumer function that will consume ",(0,n.kt)("inlineCode",{parentName:"p"},"HelloWorld")," messages\nfrom ",(0,n.kt)("em",{parentName:"p"},"hello_world")," topic and log them."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'@app.consumes()\nasync def on_hello_world(msg: HelloWorld):\n    logger.info(f"Got msg: {msg}")\n')),(0,n.kt)("p",null,"The function decorated with the ",(0,n.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator will be called\nwhen a message is produced to Kafka."),(0,n.kt)("p",null,"The message will then be injected into the typed ",(0,n.kt)("em",{parentName:"p"},"msg")," argument of the\nfunction and its type will be used to parse the message."),(0,n.kt)("p",null,"In this example case, when the message is sent into a ",(0,n.kt)("em",{parentName:"p"},"hello_world"),"\ntopic, it will be parsed into a HelloWorld class and ",(0,n.kt)("inlineCode",{parentName:"p"},"on_hello_world"),"\nfunction will be called with the parsed class as ",(0,n.kt)("em",{parentName:"p"},"msg")," argument value."),(0,n.kt)("h2",{id:"final-app"},"Final app"),(0,n.kt)("p",null,"Your app code should look like this:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'from fastkafka import FastKafka\nfrom pydantic import BaseModel, Field\nfrom fastkafka._components.logger import get_logger\n\nlogger = get_logger(__name__)\n\nclass HelloWorld(BaseModel):\n    msg: str = Field(\n        ...,\n        example="Hello",\n        description="Demo hello world message",\n    )\n\nkafka_brokers = {\n    "demo_broker": {\n        "url": "<url_of_your_kafka_bootstrap_server>",\n        "description": "local demo kafka broker",\n        "port": "<port_of_your_kafka_bootstrap_server>",\n    }\n}\n\napp = FastKafka(kafka_brokers=kafka_brokers)\n@app.consumes()\nasync def on_hello_world(msg: HelloWorld):\n    logger.info(f"Got msg: {msg}")\n')),(0,n.kt)("h2",{id:"run-the-app"},"Run the app"),(0,n.kt)("p",null,"Now we can run the app. Copy the code above in consumer_example.py and\nrun it by running"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-shell"},"fastkafka run --num-workers=1 --kafka-broker=demo_broker consumer_example:app\n")),(0,n.kt)("p",null,"After running the command, you should see this output in your terminal:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"[14442]: 23-06-15 07:16:00.564 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n[14442]: 23-06-15 07:16:00.564 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': '127.0.0.1:9092'}\n[14442]: 23-06-15 07:16:00.577 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n[14442]: 23-06-15 07:16:00.577 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'hello_world'})\n[14442]: 23-06-15 07:16:00.577 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'hello_world'}\n[14442]: 23-06-15 07:16:00.577 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n[14442]: 23-06-15 07:16:00.585 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'hello_world': 1}. \nStarting process cleanup, this may take a few seconds...\n23-06-15 07:16:04.626 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 14442...\n[14442]: 23-06-15 07:16:05.735 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n[14442]: 23-06-15 07:16:05.735 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n23-06-15 07:16:05.853 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 14442 terminated.\n")),(0,n.kt)("h2",{id:"send-the-message-to-kafka-topic"},"Send the message to kafka topic"),(0,n.kt)("p",null,"Lets send a ",(0,n.kt)("inlineCode",{parentName:"p"},"HelloWorld")," message to the ",(0,n.kt)("em",{parentName:"p"},"hello_world")," topic and check if\nour consumer kafka application has logged the received message. In your\nterminal, run:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-shell"},'echo { \\"msg\\": \\"Hello world\\" } | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>\n')),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"[15588]: 23-06-15 07:16:15.282 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n[15588]: 23-06-15 07:16:15.282 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': '127.0.0.1:9092'}\n[15588]: 23-06-15 07:16:15.294 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n[15588]: 23-06-15 07:16:15.294 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'hello_world'})\n[15588]: 23-06-15 07:16:15.295 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'hello_world'}\n[15588]: 23-06-15 07:16:15.295 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n[15588]: 23-06-15 07:16:15.302 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'hello_world': 1}. \n[15588]: 23-06-15 07:16:25.867 [INFO] consumer_example: Got msg: msg='Hello world'\nStarting process cleanup, this may take a few seconds...\n23-06-15 07:16:34.168 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 15588...\n[15588]: 23-06-15 07:16:35.358 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n[15588]: 23-06-15 07:16:35.359 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n23-06-15 07:16:35.475 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 15588 terminated.\n")),(0,n.kt)("p",null,"You should see the \u201cGot msg: msg='Hello world'\" being logged by your\nconsumer."),(0,n.kt)("h2",{id:"choosing-a-topic"},"Choosing a topic"),(0,n.kt)("p",null,"You probably noticed that you didn\u2019t define which topic you are\nreceiving the message from, this is because the ",(0,n.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator\ndetermines the topic by default from your function name. The decorator\nwill take your function name and strip the default \u201con","_",'" prefix from it\nand use the rest as the topic name. In this example case, the topic is\n',(0,n.kt)("em",{parentName:"p"},"hello_world"),"."),(0,n.kt)("p",null,"You can choose your custom prefix by defining the ",(0,n.kt)("inlineCode",{parentName:"p"},"prefix")," parameter in\nconsumes decorator, like this:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'@app.consumes(prefix="read_from_")\nasync def read_from_hello_world(msg: HelloWorld):\n    logger.info(f"Got msg: {msg}")\n')),(0,n.kt)("p",null,"Also, you can define the topic name completely by defining the ",(0,n.kt)("inlineCode",{parentName:"p"},"topic"),"\nin parameter in consumes decorator, like this:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'@app.consumes(topic="my_special_topic")\nasync def on_hello_world(msg: HelloWorld):\n    logger.info(f"Got msg: {msg}")\n')),(0,n.kt)("h2",{id:"message-data"},"Message data"),(0,n.kt)("p",null,"The message received from kafka is translated from binary JSON\nrepresentation int the class defined by typing of ",(0,n.kt)("em",{parentName:"p"},"msg")," parameter in the\nfunction decorated by the ",(0,n.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator."),(0,n.kt)("p",null,"In this example case, the message will be parsed into a ",(0,n.kt)("inlineCode",{parentName:"p"},"HelloWorld"),"\nclass."),(0,n.kt)("h2",{id:"message-metadata"},"Message metadata"),(0,n.kt)("p",null,"If you need any of Kafka message metadata such as timestamp, partition\nor headers you can access the metadata by adding a EventMetadata typed\nargument to your consumes function and the metadata from the incoming\nmessage will be automatically injected when calling the consumes\nfunction."),(0,n.kt)("p",null,"Let\u2019s demonstrate that."),(0,n.kt)("h3",{id:"create-a-consumer-function-with-metadata"},"Create a consumer function with metadata"),(0,n.kt)("p",null,"The only difference from the original basic consume function is that we\nare now passing the ",(0,n.kt)("inlineCode",{parentName:"p"},"meta: EventMetadata")," argument to the function. The\n",(0,n.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator will register that and, when a message is\nconsumed, it will also pass the metadata to your function. Now you can\nuse the metadata in your consume function. Lets log it to see what it\ncontains."),(0,n.kt)("p",null,"First, we need to import the EventMetadata"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"from fastkafka import EventMetadata\n")),(0,n.kt)("p",null,"Now we can add the ",(0,n.kt)("inlineCode",{parentName:"p"},"meta")," argument to our consuming function."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'@app.consumes()\nasync def on_hello_world(msg: HelloWorld, meta: EventMetadata):\n    logger.info(f"Got metadata: {meta}")\n')),(0,n.kt)("p",null,"Your final app should look like this:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'from fastkafka import FastKafka\nfrom pydantic import BaseModel, Field\nfrom fastkafka import EventMetadata\nfrom fastkafka._components.logger import get_logger\n\nlogger = get_logger(__name__)\nclass HelloWorld(BaseModel):\n    msg: str = Field(\n        ...,\n        example="Hello",\n        description="Demo hello world message",\n    )\nkafka_brokers = {\n    "demo_broker": {\n        "url": "<url_of_your_kafka_bootstrap_server>",\n        "description": "local demo kafka broker",\n        "port": "<port_of_your_kafka_bootstrap_server>",\n    }\n}\n\napp = FastKafka(kafka_brokers=kafka_brokers)\n@app.consumes()\nasync def on_hello_world(msg: HelloWorld, meta: EventMetadata):\n    logger.info(f"Got metadata: {meta}")\n')),(0,n.kt)("p",null,"Now lets run the app and send a message to the broker to see the logged\nmessage metadata."),(0,n.kt)("p",null,"You should see a similar log as the one below and the metadata being\nlogged in your app."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"[20050]: 23-06-15 07:18:55.661 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n[20050]: 23-06-15 07:18:55.661 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': '127.0.0.1:9092'}\n[20050]: 23-06-15 07:18:55.675 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n[20050]: 23-06-15 07:18:55.675 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'hello_world'})\n[20050]: 23-06-15 07:18:55.675 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'hello_world'}\n[20050]: 23-06-15 07:18:55.675 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n[20050]: 23-06-15 07:18:55.682 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'hello_world': 1}. \n[20050]: 23-06-15 07:19:06.337 [INFO] consumer_example: Got metadata: EventMetadata(topic='hello_world', partition=0, offset=0, timestamp=1686813546255, timestamp_type=0, key=None, value=b'{ \"msg\": \"Hello world\" }', checksum=None, serialized_key_size=-1, serialized_value_size=24, headers=())\nStarting process cleanup, this may take a few seconds...\n23-06-15 07:19:14.547 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 20050...\n[20050]: 23-06-15 07:19:15.630 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n[20050]: 23-06-15 07:19:15.630 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n23-06-15 07:19:15.742 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 20050 terminated.\n")),(0,n.kt)("p",null,"As you can see in the log, from the metadata you now have the\ninformation about the partition, offset, timestamp, key and headers.\n\ud83c\udf89"),(0,n.kt)("h2",{id:"dealing-with-high-latency-consuming-functions"},"Dealing with high latency consuming functions"),(0,n.kt)("p",null,"If your functions have high latency due to, for example, lengthy\ndatabase calls you will notice a big decrease in performance. This is\ndue to the issue of how the consumes decorator executes your consume\nfunctions when consuming events. By default, the consume function will\nrun the consuming funtions for one topic sequentially, this is the most\nstraightforward approach and results with the least amount of overhead."),(0,n.kt)("p",null,"But, to handle those high latency tasks and run them in parallel,\nFastKafka has a\n",(0,n.kt)("a",{parentName:"p",href:"/docs/next/api/fastkafka/executors/DynamicTaskExecutor#fastkafka.executors.DynamicTaskExecutor"},(0,n.kt)("inlineCode",{parentName:"a"},"DynamicTaskExecutor")),"\nprepared for your consumers. This executor comes with additional\noverhead, so use it only when you need to handle high latency functions."),(0,n.kt)("p",null,"Lets demonstrate how to use it."),(0,n.kt)("p",null,"To your consumes decorator, add an ",(0,n.kt)("inlineCode",{parentName:"p"},"executor")," option and set it to\n",(0,n.kt)("inlineCode",{parentName:"p"},'"DynamicTaskExecutor"'),", this will enable the consumer to handle high\nlatency functions effectively."),(0,n.kt)("p",null,"Your consuming function should now look like this:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'@app.consumes(executor="DynamicTaskExecutor")\nasync def on_hello_world(msg: HelloWorld):\n    logger.info(f"Got msg: {msg}")\n')),(0,n.kt)("p",null,"And the complete app should now look like this:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'from fastkafka import FastKafka\nfrom pydantic import BaseModel, Field\nfrom fastkafka._components.logger import get_logger\n\nlogger = get_logger(__name__)\n\nclass HelloWorld(BaseModel):\n    msg: str = Field(\n        ...,\n        example="Hello",\n        description="Demo hello world message",\n    )\n\nkafka_brokers = {\n    "demo_broker": {\n        "url": "<url_of_your_kafka_bootstrap_server>",\n        "description": "local demo kafka broker",\n        "port": "<port_of_your_kafka_bootstrap_server>",\n    }\n}\n\napp = FastKafka(kafka_brokers=kafka_brokers)\n\n@app.consumes(executor="DynamicTaskExecutor")\nasync def on_hello_world(msg: HelloWorld):\n    logger.info(f"Got msg: {msg}")\n')),(0,n.kt)("p",null,"You can now run your app using the CLI commands described in this guide."),(0,n.kt)("p",null,"Lets send a ",(0,n.kt)("inlineCode",{parentName:"p"},"HelloWorld")," message to the ",(0,n.kt)("em",{parentName:"p"},"hello_world")," topic and check if\nour consumer kafka application has logged the received message. In your\nterminal, run:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-shell"},'echo { \\"msg\\": \\"Hello world\\" } | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>\n')),(0,n.kt)("p",null,"You should see a similar log as the one below."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"[21539]: 23-06-15 07:19:25.135 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n[21539]: 23-06-15 07:19:25.135 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': '127.0.0.1:9092'}\n[21539]: 23-06-15 07:19:25.147 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n[21539]: 23-06-15 07:19:25.147 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'hello_world'})\n[21539]: 23-06-15 07:19:25.147 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'hello_world'}\n[21539]: 23-06-15 07:19:25.147 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n[21539]: 23-06-15 07:19:25.154 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'hello_world': 1}. \n[21539]: 23-06-15 07:19:35.512 [INFO] consumer_example: Got msg: msg='Hello world'\nStarting process cleanup, this may take a few seconds...\n23-06-15 07:19:44.023 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 21539...\n[21539]: 23-06-15 07:19:45.202 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n[21539]: 23-06-15 07:19:45.203 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n23-06-15 07:19:45.313 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 21539 terminated.\n")),(0,n.kt)("p",null,"Inside the log, you should see the \u201cGot msg: msg='Hello world'\" being\nlogged by your consumer."))}u.isMDXComponent=!0}}]);