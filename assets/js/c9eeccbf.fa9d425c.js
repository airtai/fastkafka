"use strict";(self.webpackChunkfastkafka=self.webpackChunkfastkafka||[]).push([[3747],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>f});var o=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=o.createContext({}),c=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=c(e.components);return o.createElement(l.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),p=c(n),d=a,f=p["".concat(l,".").concat(d)]||p[d]||m[d]||r;return n?o.createElement(f,s(s({ref:t},u),{},{components:n})):o.createElement(f,s({ref:t},u))}));function f(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,s=new Array(r);s[0]=d;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[p]="string"==typeof e?e:a,s[1]=i;for(var c=2;c<r;c++)s[c]=n[c];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},9709:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>c});var o=n(7462),a=(n(7294),n(3905));const r={},s="Batch consuming",i={unversionedId:"guides/Guide_12_Batch_Consuming",id:"version-0.7.1/guides/Guide_12_Batch_Consuming",title:"Batch consuming",description:"If you want to consume data in batches @consumes decorator makes that",source:"@site/versioned_docs/version-0.7.1/guides/Guide_12_Batch_Consuming.md",sourceDirName:"guides",slug:"/guides/Guide_12_Batch_Consuming",permalink:"/docs/0.7.1/guides/Guide_12_Batch_Consuming",draft:!1,tags:[],version:"0.7.1",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"@consumes basics",permalink:"/docs/0.7.1/guides/Guide_11_Consumes_Basics"},next:{title:"@produces basics",permalink:"/docs/0.7.1/guides/Guide_21_Produces_Basics"}},l={},c=[{value:"Consume function with batching",id:"consume-function-with-batching",level:2},{value:"App example",id:"app-example",level:2},{value:"Send the messages to kafka topic",id:"send-the-messages-to-kafka-topic",level:2}],u={toc:c},p="wrapper";function m(e){let{components:t,...n}=e;return(0,a.kt)(p,(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"batch-consuming"},"Batch consuming"),(0,a.kt)("p",null,"If you want to consume data in batches ",(0,a.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator makes that\npossible for you. By typing a consumed msg object as a ",(0,a.kt)("inlineCode",{parentName:"p"},"list")," of\nmessages the consumer will call your consuming function with a batch of\nmessages consumed from a single partition. Let\u2019s demonstrate that now."),(0,a.kt)("h2",{id:"consume-function-with-batching"},"Consume function with batching"),(0,a.kt)("p",null,"To consume messages in batches, you need to wrap you message type into a\nlist and the ",(0,a.kt)("inlineCode",{parentName:"p"},"@consumes")," decorator will take care of the rest for you.\nYour consumes function will be called with batches grouped by partition\nnow."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'@app.consumes(auto_offset_reset="earliest")\nasync def on_hello_world(msg: List[HelloWorld]):\n    logger.info(f"Got msg batch: {msg}")\n')),(0,a.kt)("h2",{id:"app-example"},"App example"),(0,a.kt)("p",null,"We will modify the app example from ",(0,a.kt)("a",{parentName:"p",href:"/docs/next/guides/Guide_11_Consumes_Basics"},"@consumes\nbasics")," guide to consume\n",(0,a.kt)("inlineCode",{parentName:"p"},"HelloWorld")," messages batch. The final app will look like this (make\nsure you replace the ",(0,a.kt)("inlineCode",{parentName:"p"},"<url_of_your_kafka_bootstrap_server>")," and\n",(0,a.kt)("inlineCode",{parentName:"p"},"<port_of_your_kafka_bootstrap_server>")," with the actual values):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\nimport asyncio\nfrom typing import List\nfrom pydantic import BaseModel, Field\n\nfrom fastkafka import FastKafka\nfrom fastkafka._components.logger import get_logger\n\nlogger = get_logger(__name__)\n\nclass HelloWorld(BaseModel):\n    msg: str = Field(\n        ...,\n        example="Hello",\n        description="Demo hello world message",\n    )\n\nkafka_brokers = {\n    "demo_broker": {\n        "url": "<url_of_your_kafka_bootstrap_server>",\n        "description": "local demo kafka broker",\n        "port": "<port_of_your_kafka_bootstrap_server>",\n    }\n}\n\napp = FastKafka(kafka_brokers=kafka_brokers)\n\n@app.consumes(auto_offset_reset="earliest")\nasync def on_hello_world(msg: List[HelloWorld]):\n    logger.info(f"Got msg batch: {msg}")\n')),(0,a.kt)("h2",{id:"send-the-messages-to-kafka-topic"},"Send the messages to kafka topic"),(0,a.kt)("p",null,"Lets send a couple of ",(0,a.kt)("inlineCode",{parentName:"p"},"HelloWorld")," messages to the ",(0,a.kt)("em",{parentName:"p"},"hello_world")," topic\nand check if our consumer kafka application has logged the received\nmessages batch. In your terminal, run the following command at least two\ntimes to create multiple messages in your kafka queue:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'echo {\\"msg\\": \\"Hello world\\"} | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>\n')),(0,a.kt)("p",null,"Now we can run the app. Copy the code of the example app in\nconsumer_example.py and run it by running"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"fastkafka run --num-workers=1 --kafka-broker=demo_broker consumer_example:app\n")),(0,a.kt)("p",null,"You should see the your Kafka messages being logged in batches by your\nconsumer."))}m.isMDXComponent=!0}}]);